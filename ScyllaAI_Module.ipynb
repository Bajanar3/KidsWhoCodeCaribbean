{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "name": "ScyllaAI Module.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bajanar3/KidsWhoCodeCaribbean/blob/main/ScyllaAI_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-18T19:15:05.598667Z",
          "start_time": "2021-11-18T19:15:05.588670Z"
        },
        "id": "3455b100"
      },
      "source": [
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2"
      ],
      "id": "3455b100",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-18T18:51:49.508352Z",
          "start_time": "2021-11-18T18:51:20.438401Z"
        },
        "id": "f20caf4b",
        "outputId": "d5d8293e-3ee2-480e-a686-fe1ed695be26"
      },
      "source": [
        "scylla = tf.keras.models.load_model(\"G:/My Drive/My Trained Models/ScyllaAI_v0.hdf5\")\n",
        "scylla.trainable = False\n",
        "scylla.summary()"
      ],
      "id": "f20caf4b",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"scylla output\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Img input layer (InputLayer)   [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " fish_seeker (Sequential)       (None, 1)            70656408    ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " grunts (Sequential)            (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " lionfish (Sequential)          (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " parrotfish (Sequential)        (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " pufferfish (Sequential)        (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " sargemajor (Sequential)        (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " surgeonfish (Sequential)       (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " trumpetfish (Sequential)       (None, 1)            5690532     ['Img input layer[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8)            0           ['fish_seeker[0][0]',            \n",
            "                                                                  'grunts[0][0]',                 \n",
            "                                                                  'lionfish[0][0]',               \n",
            "                                                                  'parrotfish[0][0]',             \n",
            "                                                                  'pufferfish[0][0]',             \n",
            "                                                                  'sargemajor[0][0]',             \n",
            "                                                                  'surgeonfish[0][0]',            \n",
            "                                                                  'trumpetfish[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,490,132\n",
            "Trainable params: 0\n",
            "Non-trainable params: 110,490,132\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-18T19:27:53.345348Z",
          "start_time": "2021-11-18T19:27:53.322149Z"
        },
        "id": "18e0b61c",
        "outputId": "564629ae-5651-4de4-9b85-5f2b3aafd065"
      },
      "source": [
        "class ScyllaAI():\n",
        "    import tensorflow as tf\n",
        "    import cv2\n",
        "    import pandas as pd\n",
        "    \n",
        "    def __init__(self, \n",
        "                 model, \n",
        "                 img_file_path=None,\n",
        "                 sec=0, count=0,\n",
        "                 frame_rate=0.2, \n",
        "                 video_filepath=None,\n",
        "                 *args,\n",
        "                 **kwargs):\n",
        "        self.model = model\n",
        "        self.img_file_path = img_file_path\n",
        "        self.frame_rate = frame_rate\n",
        "        self.video_filepath = video_filepath\n",
        "        self.sec = sec\n",
        "        self.count = count\n",
        "        self.model.trainable=False\n",
        "        super().__init__()\n",
        "        return\n",
        "    \n",
        "    def look_at_frame(self, vidcap):\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC, self.sec*1000)\n",
        "        has_frames, image = vidcap.read()\n",
        "        if has_frames:\n",
        "            try:\n",
        "                frame = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = tf.expand_dims(frame, axis=0)\n",
        "                analysis = self.model.predict(frame)\n",
        "                analysis = np.round(analysis, 5)\n",
        "                output = analysis.ravel()\n",
        "                print(f\"Analytics: {ouput}\")\n",
        "            except:\n",
        "                print(\"Execution error occured when getting video frames.\")\n",
        "                has_frames = False\n",
        "                pass\n",
        "        return has_frames\n",
        "    \n",
        "    def get_frame(self, vidcap):\n",
        "        vidcap.set(cv2.CAP_PROP_POS_MSEC, self.sec*1000)\n",
        "        has_frames, image = vidcap.read()\n",
        "        if has_frames:\n",
        "            try:\n",
        "                cv2.imwrite(str(self.saved_image_directory) + str(image_label) + str(count) + str(image_format), image)\n",
        "            except:\n",
        "                print(\"Execution error occured when getting video frames.\")\n",
        "                has_frames = False\n",
        "                pass\n",
        "        return has_frames \n",
        "    \n",
        "    def analyse_from_video(self):\n",
        "        self.sec = 0 \n",
        "        vidcap = cv2.VideoCapture(self.video_filepath)\n",
        "        success = ScyllaAI.look_at_frame(self.sec, vidcap)\n",
        "        while success:\n",
        "            self.count += 1\n",
        "            self.sec = self.sec + self.frame_rate\n",
        "            self.sec = round(self.sec, 2)\n",
        "            success = ScyllaAI.look_at_frame(self.sec,vidcap)\n",
        "        print(\"Process completed.\")\n",
        "    \n",
        "     def build_image_dataset(self):\n",
        "        self.sec = 0 \n",
        "        vidcap = cv2.VideoCapture(self.video_filepath)\n",
        "        success = ScyllaAI.look_at_frame(self.sec, vidcap)\n",
        "        while success:\n",
        "            self.count += 1\n",
        "            self.sec = self.sec + self.frame_rate\n",
        "            self.sec = round(self.sec, 2)\n",
        "            success = ScyllaAI.look_at_frame(self.sec,vidcap)\n",
        "        print(\"Process completed.\")\n",
        "            \n",
        "    if __name__ == \"__main__\":\n",
        "        print(\"Scylla object has been loaded.\")\n",
        "    pass"
      ],
      "id": "18e0b61c",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scylla object has been loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-11-18T19:27:59.847262Z",
          "start_time": "2021-11-18T19:27:59.720846Z"
        },
        "id": "95a421ba",
        "outputId": "160a51a0-ce18-4897-ec64-eefb24fdf73d"
      },
      "source": [
        "video_filepath = \"/Users/steve/Downloads/Vauxhall test.mp4\"\n",
        "ScyllaAI(scylla, video_filepath=video_filepath).analyse_from_video()"
      ],
      "id": "95a421ba",
      "execution_count": null,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'sec'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/1785463608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/Users/steve/Downloads/Vauxhall test.mp4\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mScyllaAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscylla\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo_filepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvideo_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyse_from_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/2207043871.py\u001b[0m in \u001b[0;36manalyse_from_video\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mvidcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScyllaAI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlook_at_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11024/2207043871.py\u001b[0m in \u001b[0;36mlook_at_frame\u001b[1;34m(self, vidcap)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlook_at_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_POS_MSEC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mhas_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_frames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'sec'"
          ]
        }
      ]
    }
  ]
}